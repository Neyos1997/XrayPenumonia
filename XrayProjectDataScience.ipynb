{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "import cv2\n",
    "import os\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, MaxPool2D, Conv2D, Input, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Set the path to the dataset\n",
    "input_path = r'C:\\Users\\wmonsri\\Desktop\\chest_xray'\n",
    "model_location = r'C:\\Users\\wmonsri\\Desktop\\xray\\best_model.h5'\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(15, 7))  \n",
    "ax = ax.ravel()  \n",
    "plt.tight_layout()\n",
    "for i, _set in enumerate(['train', 'val', 'test']):\n",
    "    set_path = os.path.join(input_path, _set)\n",
    "    ax[i].imshow(plt.imread(os.path.join(set_path, 'NORMAL', os.listdir(os.path.join(set_path, 'NORMAL'))[0])), cmap='gray')\n",
    "    ax[i].set_title(f'set{_set}, Condition: NORMAL')\n",
    "    ax[i+3].imshow(plt.imread(os.path.join(set_path, 'PNEUMONIA', os.listdir(os.path.join(set_path, 'PNEUMONIA'))[0])), cmap='gray')\n",
    "    ax[i+3].set_title(f'set{_set}, Condition: PNEUMONIA')\n",
    "plt.show()\n",
    "\n",
    "for _set in ['train', 'val', 'test']:\n",
    "    print(os.path.join(input_path, _set))\n",
    "    n_normal = len(os.listdir(os.path.join(input_path, _set, 'NORMAL')))\n",
    "    n_pneumonia = len(os.listdir(os.path.join(input_path, _set, 'PNEUMONIA')))\n",
    "    print(f'{_set}, normal images {n_normal}, pneumonia images {n_pneumonia}')\n",
    "\n",
    "\n",
    "def process_data(img_dim, batch_size):\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, vertical_flip=True)\n",
    "    test_val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "        directory=os.path.join(input_path, 'train'),\n",
    "        target_size=(img_dim, img_dim),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    test_gen = test_val_datagen.flow_from_directory(\n",
    "        directory=os.path.join(input_path, 'test'),\n",
    "        target_size=(img_dim, img_dim),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "    for cond in ['NORMAL', 'PNEUMONIA']:\n",
    "        for img in os.listdir(os.path.join(input_path, 'test', cond)):\n",
    "            img_path = os.path.join(input_path, 'test', cond, img)\n",
    "            img = plt.imread(img_path)\n",
    "            img = cv2.resize(img, (img_dim, img_dim))\n",
    "            img = np.dstack([img, img, img])\n",
    "            img = img.astype('float32') / 255\n",
    "            label = 0 if cond == 'NORMAL' else 1\n",
    "            test_data.append(img)\n",
    "            test_labels.append(label)\n",
    "        \n",
    "    test_data = np.array(test_data)\n",
    "    test_labels = np.array(test_labels)\n",
    "    return train_gen, test_gen, test_data, test_labels\n",
    "\n",
    "# Set image dimensions, epochs, and batch size\n",
    "img_dims = 150\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_gen, test_gen, test_data, test_labels = process_data(img_dims, batch_size)\n",
    "\n",
    "\n",
    "if os.path.exists(model_location):\n",
    "    model = load_model(model_location)\n",
    "    print(\"Loaded model from disk\")\n",
    "else:\n",
    "    inputs = Input(shape=(img_dims, img_dims, 3))\n",
    "    X = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
    "    X = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(X)\n",
    "    X = MaxPool2D(pool_size=(2, 2))(X)\n",
    "    \n",
    "    # Add more layers as needed\n",
    "\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(units=1, activation='sigmoid')(X)  # Ensure only one unit in the output layer for binary classification\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=inputs, outputs=X)\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint(filepath=model_location, save_best_only=True, save_weights_only=False)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min') #we should remove the early stopping and test\n",
    "\n",
    "# Train the model\n",
    "history = model.fit_generator(\n",
    "    train_gen, \n",
    "    steps_per_epoch=train_gen.samples // batch_size,\n",
    "    epochs=epochs, \n",
    "    validation_data=test_gen, \n",
    "    validation_steps=test_gen.samples // batch_size, \n",
    "    callbacks=[checkpoint, lr_reduce, early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba5d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from langchain.llms import CTransformers\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "# Set the path to the dataset\n",
    "input_path = r'C:\\Users\\wmonsri\\Desktop\\chest_xray\\test'\n",
    "\n",
    "# Set the location to load the model\n",
    "model_location = r'C:\\Users\\wmonsri\\Desktop\\xray\\best_model.h5'\n",
    "\n",
    "# Load the model\n",
    "if os.path.exists(model_location):\n",
    "    model = load_model(model_location)\n",
    "    print(\"Loaded CNN model from disk\")\n",
    "else:\n",
    "    print(\"CNN Model not found. Please train the model first.\")\n",
    "\n",
    "# Function to process test data with NLP analysis\n",
    "def process_test_data_with_nlp(img_dim):\n",
    "    test_data = []\n",
    "    image_paths = []\n",
    "    for class_folder in ['NORMAL', 'PNEUMONIA']:\n",
    "        class_path = os.path.join(input_path, class_folder)\n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            img = cv2.resize(cv2.imread(img_path, cv2.IMREAD_COLOR), (img_dim, img_dim))\n",
    "            test_data.append(img)\n",
    "            image_paths.append(img_path)\n",
    "    return test_data, image_paths\n",
    "\n",
    "def contour_lungs(img):\n",
    "    # Convert the image to grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred_img = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "\n",
    "    # Apply adaptive thresholding to segment the lungs\n",
    "    _, threshold_img = cv2.threshold(blurred_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(threshold_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a mask to draw the contours\n",
    "    contour_mask = np.zeros_like(img)\n",
    "\n",
    "    # Draw contours on the mask\n",
    "    cv2.drawContours(contour_mask, contours, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Convert the mask to grayscale\n",
    "    contour_mask_gray = cv2.cvtColor(contour_mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate the opacity degree based on the contour area\n",
    "    total_area = img.shape[0] * img.shape[1]\n",
    "    highlighted_area = cv2.countNonZero(contour_mask_gray)\n",
    "    opacity_degree = (highlighted_area / total_area) * 100  # Opacity as a percentage\n",
    "\n",
    "    # Apply the mask to the original image to get the contoured image\n",
    "    contoured_img = cv2.bitwise_and(img, img, mask=contour_mask_gray)\n",
    "\n",
    "    return contoured_img, opacity_degree\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "def generate_nlp_interpretation(img_name, probability, opacity_degree):\n",
    "    # Generate textual summary for the finding\n",
    "    text = f\"Probability of Pneumonia: {probability}\\nOpacity Degree of Lungs: {opacity_degree:.2f}%\"\n",
    "    return text\n",
    "\n",
    "# Initialize LLM model\n",
    "llm = CTransformers(model=\"TheBloke/Llama-2-13B-Ensemble-v5-GGUF\", model_file=\"llama-2-13b-ensemble-v5.Q2_K.gguf\", model_type=\"llama\")\n",
    "\n",
    "# Define template\n",
    "template = \"\"\"\n",
    "              Describe the findings in the following image: `{image_name}`.\n",
    "              Condition: Pneumonia\n",
    "              Probability of Pneumonia (CNN Model): {probability}\n",
    "              Opacity Degree of Lungs: {opacity_degree:.2f}%\n",
    "              Return your response in bullet points which covers the key points of the findings.\n",
    "              ```{text}```\n",
    "              interpret these results to confirm or deny if it is a case of pneumonia.\n",
    "              BULLET POINT SUMMARY:\n",
    "              - Condition: Pneumonia\n",
    "              - Probability of Pneumonia (CNN Model): {probability}\n",
    "              - Opacity Degree of Lungs: {opacity_degree:.2f}%\n",
    "           \"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"image_name\", \"probability\", \"opacity_degree\", \"text\"])\n",
    "\n",
    "# Initialize LLMChain\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# Set image dimensions\n",
    "img_dims = 150\n",
    "\n",
    "# Process the test data and generate NLP interpretations\n",
    "test_data, image_paths = process_test_data_with_nlp(img_dims)\n",
    "\n",
    "# Check if test_data is empty\n",
    "if not test_data:\n",
    "    print(\"No test data found. Please check your data loading logic.\")\n",
    "else:\n",
    "    # Analyze images and generate interpretations\n",
    "    for img, img_path in zip(test_data, image_paths):\n",
    "        img_name = os.path.basename(img_path)\n",
    "        print(f\"Image Name: {img_name}\")\n",
    "        \n",
    "        # Predict using pre-trained CNN model\n",
    "        probability = model.predict(np.array([img]))[0][0]\n",
    "        \n",
    "        # Contour lungs and calculate opacity degree\n",
    "        contoured_img, opacity_degree = contour_lungs(img)\n",
    "        \n",
    "        # Display the original and contoured images side by side\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axes[0].set_title(\"Original Image\")\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Highlight opacity in red on the contoured image\n",
    "        contoured_with_opacity = np.copy(contoured_img)\n",
    "        contoured_with_opacity[:, :, 0] = np.where(contoured_with_opacity[:, :, 0] == 0, 0, 255)\n",
    "        axes[1].imshow(cv2.cvtColor(contoured_with_opacity, cv2.COLOR_BGR2RGB))\n",
    "        axes[1].set_title(\"Contoured Lungs (Opacity Highlighted)\")\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Print opacity degree, probability, and image name\n",
    "        print(f\"Opacity Degree of Lungs: {opacity_degree:.2f}%\")\n",
    "        print(f\"Probability of Pneumonia: {probability}\")\n",
    "        \n",
    "        # Generate NLP interpretation\n",
    "        nlp_interpretation = llm_chain.run({'image_name': img_name, 'probability': probability, 'opacity_degree': opacity_degree, 'text': ''})\n",
    "\n",
    "        print(\"Findings Summary:\")\n",
    "        print(nlp_interpretation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d7750a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wmonsri\\Anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:h5py._conv:Creating converter from 3 to 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wmonsri\\Anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wmonsri\\Anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wmonsri\\Anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wmonsri\\Anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "INFO:root:Loaded CNN model from disk\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/TheBloke/Llama-2-13B-Ensemble-v5-GGUF/revision/main HTTP/1.1\" 200 1742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499d43d0f6a64e3db38b495827ecfb4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/TheBloke/Llama-2-13B-Ensemble-v5-GGUF/revision/main HTTP/1.1\" 200 1742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f9624b2557490f827b1baf4bf22907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:15] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:15] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:15] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:17] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:19] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:21] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:23] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 323ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wmonsri\\Anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:25] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:27] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:30] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:31] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:34] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:36] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:38] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:40] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:42] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:44] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:46] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:48] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:50] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:52] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:54] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:56] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:24:58] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:00] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:02] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:04] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:06] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:08] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:10] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:12] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:14] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:16] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:18] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:20] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:22] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:24] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:26] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:28] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:30] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:25:32] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:26:09] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:09] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:26] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image path: C:\\Users\\wmonsri\\Desktop\\process\\processed_IM-0122-0001.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:31] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:33] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:35] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:37] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:39] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:41] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:43] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:45] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:47] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:49] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:51] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:53] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:55] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:57] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:27:59] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:01] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:03] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:05] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:07] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:10] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:12] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:14] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:16] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:18] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:20] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:22] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:24] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:26] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:28] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:30] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:31] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:33] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:35] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:37] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:39] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:41] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:43] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:45] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:47] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:49] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:51] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:53] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:55] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:57] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:28:59] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:01] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:03] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:05] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:07] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:09] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:11] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:13] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:15] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:17] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:19] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:21] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:23] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:25] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:27] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:29] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:31] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:33] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:35] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:37] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:39] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:41] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:43] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:45] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:47] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:49] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:51] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:53] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:55] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:57] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:29:59] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:01] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:03] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:05] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:07] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:09] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:11] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:13] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:15] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:17] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:19] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:21] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:23] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:25] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:27] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:29] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:31] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:33] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:35] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:37] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:39] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:41] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:43] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:46] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:48] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:50] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:52] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:54] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:56] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:30:58] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:00] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:02] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:04] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:06] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:08] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:10] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:12] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:14] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:16] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:18] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:20] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:22] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:24] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:26] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:28] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:30] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:32] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:34] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:36] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:38] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:40] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:31:42] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:32:09] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [07/Mar/2024 14:33:09] \"\u001b[33mGET /update HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "from werkzeug.utils import secure_filename\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import logging\n",
    "from langchain.llms import CTransformers\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "app = Flask(__name__, template_folder=r'C:\\Users\\wmonsri\\Desktop\\templates')\n",
    "app.config['UPLOAD_FOLDER'] = 'uploads'\n",
    "\n",
    "# Set the location to load the CNN model\n",
    "cnn_model_location = 'C:\\\\Users\\\\wmonsri\\\\Desktop\\\\xray\\\\best_model.h5'\n",
    "if os.path.exists(cnn_model_location):\n",
    "    cnn_model = load_model(cnn_model_location)\n",
    "    logging.info(\"Loaded CNN model from disk\")\n",
    "else:\n",
    "    logging.error(\"CNN Model not found. Please train the model first.\")\n",
    "\n",
    "# Initialize LLM model\n",
    "llm = CTransformers(model=\"TheBloke/Llama-2-13B-Ensemble-v5-GGUF\",\n",
    "                    model_file=\"llama-2-13b-ensemble-v5.Q2_K.gguf\",\n",
    "                    model_type=\"llama\")\n",
    "\n",
    "# Define template\n",
    "template = \"\"\"\n",
    "              Describe the findings in the following image: `{image_name}`.\n",
    "              Condition: Pneumonia\n",
    "              Probability of Pneumonia (CNN Model): {probability}\n",
    "              Opacity Degree of Lungs: {opacity_degree:.2f}%\n",
    "              Return your response in bullet points which covers the key points of the findings.\n",
    "              ```{text}```\n",
    "              interpret these results to confirm or deny if it is a case of pneumonia.\n",
    "              BULLET POINT SUMMARY:\n",
    "              - Condition: Pneumonia\n",
    "              - Probability of Pneumonia (CNN Model): {probability}\n",
    "              - Opacity Degree of Lungs: {opacity_degree:.2f}%\n",
    "           \"\"\"\n",
    "\n",
    "# Initialize LLMChain\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"image_name\", \"probability\", \"opacity_degree\", \"text\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "\n",
    "# Function to contour lungs and calculate opacity degree\n",
    "def contour_lungs(img):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_img = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "    _, threshold_img = cv2.threshold(blurred_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(threshold_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_mask = np.zeros_like(img)\n",
    "    cv2.drawContours(contour_mask, contours, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "    contour_mask_gray = cv2.cvtColor(contour_mask, cv2.COLOR_BGR2GRAY)\n",
    "    total_area = img.shape[0] * img.shape[1]\n",
    "    highlighted_area = cv2.countNonZero(contour_mask_gray)\n",
    "    opacity_degree = (highlighted_area / total_area) * 100\n",
    "    contoured_img = cv2.bitwise_and(img, img, mask=contour_mask_gray)\n",
    "    contoured_img[:, :, 0] = np.where(contour_mask_gray == 255, 255, contoured_img[:, :, 0])  # Highlight opacity in blue color\n",
    "    contoured_img[:, :, 1] = np.where(contour_mask_gray == 255, 0, contoured_img[:, :, 1])\n",
    "    contoured_img[:, :, 2] = np.where(contour_mask_gray == 255, 0, contoured_img[:, :, 2])\n",
    "    return contoured_img, opacity_degree\n",
    "\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    if request.method == 'POST':\n",
    "        if 'file' not in request.files:\n",
    "            return jsonify({'error': 'No file part'})\n",
    "\n",
    "        file = request.files['file']\n",
    "        if file.filename == '':\n",
    "            return jsonify({'error': 'No selected file'})\n",
    "\n",
    "        # Read the uploaded image\n",
    "        image = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "        contoured_img, opacity_degree = contour_lungs(image)\n",
    "\n",
    "        # Resize the processed image to match the input shape of the model (if necessary)\n",
    "        resized_img = cv2.resize(contoured_img, (150, 150))\n",
    "\n",
    "        # Predict using the pre-trained CNN model\n",
    "        probability = cnn_model.predict(np.expand_dims(resized_img, axis=0))[0][0]\n",
    "\n",
    "        # Convert probability to Python float\n",
    "        probability = float(probability)\n",
    "\n",
    "        # Generate NLP interpretation\n",
    "        nlp_interpretation = llm_chain.run(\n",
    "            {'image_name': file.filename, 'probability': probability, 'opacity_degree': opacity_degree, 'text': ''})\n",
    "\n",
    "        # Debugging: Print processed image path\n",
    "        processed_img_name = 'processed_' + secure_filename(file.filename)\n",
    "        processed_img_path = os.path.join('C:\\\\Users\\\\wmonsri\\\\Desktop\\\\process', processed_img_name)\n",
    "        print(\"Processed image path:\", processed_img_path)\n",
    "\n",
    "        # Save the processed image\n",
    "        cv2.imwrite(processed_img_path, contoured_img)\n",
    "\n",
    "        return jsonify({'processedImagePath': processed_img_path,\n",
    "                        'probability': probability,\n",
    "                        'opacityPercentage': opacity_degree,\n",
    "                        'nlpInterpretation': nlp_interpretation})\n",
    "\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7bc826",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643b6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
